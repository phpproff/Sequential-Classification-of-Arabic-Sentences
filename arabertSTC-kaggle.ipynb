{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport string\n\ndef process_md_lines(lines):\n    lines.append('\\n')\n    ids = []\n    urls = []\n    labels = []\n    texts = []\n    orders = []\n    total_lines = []\n    id = -1\n    url = ''\n    order = 0\n    for line in lines:\n        if line[0] == '#':\n            id = int(line[line.index('[') + 1: line.index(']')])\n            url = line[line.index(']') + 1:]\n            order = 0\n        elif line != '\\n':\n            tokens = line.split('\\t')\n            labels.append(tokens[0])\n            text = tokens[1].lower().translate(str.maketrans('', '', string.punctuation))\n            texts.append(text)\n            orders.append(order)\n            order = order + 1\n            ids.append(id)\n            urls.append(url)\n        elif line == '\\n':\n            for i in range(order):\n                total_lines.append(order)\n            order = 0\n            id = -1\n            url = ''\n    df = pd.DataFrame(\n        {'id': ids, 'text': texts, 'order': orders, 'total_lines': total_lines, 'url': urls, 'label': labels})\n    return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-10T23:45:20.895562Z","iopub.execute_input":"2023-02-10T23:45:20.895938Z","iopub.status.idle":"2023-02-10T23:45:26.958089Z","shell.execute_reply.started":"2023-02-10T23:45:20.895855Z","shell.execute_reply":"2023-02-10T23:45:26.956867Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport string\ntraining_lines = open('/kaggle/input/sequentialtext/training.txt','r',encoding='utf-8').readlines()\ntesting_lines = open('/kaggle/input/sequentialtext/testing.txt','r',encoding='utf-8').readlines()\nvalidation_lines = open('/kaggle/input/sequentialtext/validation.txt','r',encoding='utf-8').readlines()\n#lines = open('drive/My Drive/hamdan/data.txt','r',encoding='utf=8').readlines()\ntraining_df = process_md_lines(training_lines)\ntesting_df = process_md_lines(testing_lines)\nvalidation_df = process_md_lines(validation_lines)\ntraining_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:45:55.782925Z","iopub.execute_input":"2023-02-10T23:45:55.783515Z","iopub.status.idle":"2023-02-10T23:46:01.883374Z","shell.execute_reply.started":"2023-02-10T23:45:55.783479Z","shell.execute_reply":"2023-02-10T23:46:01.882385Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    id                                               text  order  total_lines  \\\n0  290  الشريان الأبهر هو أكبر شريان في الجسم وهو ينقل...      0           89   \n1  290  بشكل عام يكون تضيق الأبهر موجودا لدى المصاب من...      1           89   \n2  290  وغالبا ما يصاحب تضيق الأبهر عيوب أخرى في القلب...      2           89   \n3  290  تعتمد أعراض تضيق الأبهر على شدة الحالة فمعظم ا...      3           89   \n4  290  قد يبدأ ظهور الأعراض على الأطفال المصابين بتضي...      4           89   \n\n                                                 url     label  \n0  https://www.mayoclinic.org/ar/diseases-conditi...  Overview  \n1  https://www.mayoclinic.org/ar/diseases-conditi...  Overview  \n2  https://www.mayoclinic.org/ar/diseases-conditi...  Overview  \n3  https://www.mayoclinic.org/ar/diseases-conditi...  Symptoms  \n4  https://www.mayoclinic.org/ar/diseases-conditi...  Symptoms  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>order</th>\n      <th>total_lines</th>\n      <th>url</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>290</td>\n      <td>الشريان الأبهر هو أكبر شريان في الجسم وهو ينقل...</td>\n      <td>0</td>\n      <td>89</td>\n      <td>https://www.mayoclinic.org/ar/diseases-conditi...</td>\n      <td>Overview</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>290</td>\n      <td>بشكل عام يكون تضيق الأبهر موجودا لدى المصاب من...</td>\n      <td>1</td>\n      <td>89</td>\n      <td>https://www.mayoclinic.org/ar/diseases-conditi...</td>\n      <td>Overview</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>290</td>\n      <td>وغالبا ما يصاحب تضيق الأبهر عيوب أخرى في القلب...</td>\n      <td>2</td>\n      <td>89</td>\n      <td>https://www.mayoclinic.org/ar/diseases-conditi...</td>\n      <td>Overview</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>290</td>\n      <td>تعتمد أعراض تضيق الأبهر على شدة الحالة فمعظم ا...</td>\n      <td>3</td>\n      <td>89</td>\n      <td>https://www.mayoclinic.org/ar/diseases-conditi...</td>\n      <td>Symptoms</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>290</td>\n      <td>قد يبدأ ظهور الأعراض على الأطفال المصابين بتضي...</td>\n      <td>4</td>\n      <td>89</td>\n      <td>https://www.mayoclinic.org/ar/diseases-conditi...</td>\n      <td>Symptoms</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip -q install optuna==2.3.0\n!pip -q install farasapy\n!pip -q install pyarabic\n!git clone https://github.com/aub-mind/arabert\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:46:32.324874Z","iopub.execute_input":"2023-02-10T23:46:32.325235Z","iopub.status.idle":"2023-02-10T23:47:26.247958Z","shell.execute_reply.started":"2023-02-10T23:46:32.325203Z","shell.execute_reply":"2023-02-10T23:47:26.246585Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'arabert'...\nremote: Enumerating objects: 600, done.\u001b[K\nremote: Counting objects: 100% (65/65), done.\u001b[K\nremote: Compressing objects: 100% (33/33), done.\u001b[K\nremote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\nReceiving objects: 100% (600/600), 9.14 MiB | 19.34 MiB/s, done.\nResolving deltas: 100% (339/339), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\ntraining_df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:47:26.250813Z","iopub.execute_input":"2023-02-10T23:47:26.251230Z","iopub.status.idle":"2023-02-10T23:47:26.619559Z","shell.execute_reply.started":"2023-02-10T23:47:26.251188Z","shell.execute_reply":"2023-02-10T23:47:26.618378Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['Overview', 'Symptoms', 'Causes', 'Diagnosis', 'Treatment'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"hard_map = { 0 : 'Overview', 1: 'Causes', 2 : 'Symptoms', 3: 'Treatment', 4:'Diagnosis'}\nlabel_list_HARD = ['Overview', 'Causes', 'Symptoms', 'Treatment', 'Diagnosis']","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:47:26.621048Z","iopub.execute_input":"2023-02-10T23:47:26.621801Z","iopub.status.idle":"2023-02-10T23:47:26.627794Z","shell.execute_reply.started":"2023-02-10T23:47:26.621757Z","shell.execute_reply":"2023-02-10T23:47:26.626684Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from arabert.preprocess import ArabertPreprocessor\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n\nfrom transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\nfrom transformers.data.processors import SingleSentenceClassificationProcessor\nfrom transformers import Trainer , TrainingArguments\nfrom transformers.trainer_utils import EvaluationStrategy\nfrom transformers.data.processors.utils import InputFeatures\n","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:47:26.630181Z","iopub.execute_input":"2023-02-10T23:47:26.631198Z","iopub.status.idle":"2023-02-10T23:47:30.357236Z","shell.execute_reply.started":"2023-02-10T23:47:26.631157Z","shell.execute_reply":"2023-02-10T23:47:30.355865Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# https://huggingface.co/aubmindlab/bert-base-arabertv02\ndataset_name = 'medical'\nmodel_name = 'aubmindlab/bert-base-arabertv02'\ntask_name = 'classification'\nmax_len = 256\narabert_prep = ArabertPreprocessor(model_name.split(\"/\")[-1])\n\ntraining_df['text'] = training_df['text'].apply(lambda x:   arabert_prep.preprocess(x))\ntraining_df['text']","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:47:59.648925Z","iopub.execute_input":"2023-02-10T23:47:59.649993Z","iopub.status.idle":"2023-02-10T23:48:47.606292Z","shell.execute_reply.started":"2023-02-10T23:47:59.649952Z","shell.execute_reply":"2023-02-10T23:48:47.605290Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0         الشريان الأبهر هو أكبر شريان في الجسم وهو ينقل...\n1         بشكل عام يكون تضيق الأبهر موجودا لدى المصاب من...\n2         وغالبا ما يصاحب تضيق الأبهر عيوب أخرى في القلب...\n3         تعتمد أعراض تضيق الأبهر على شدة الحالة فمعظم ا...\n4         قد يبدأ ظهور الأعراض على الأطفال المصابين بتضي...\n                                ...                        \n296720    إذا كنت والد طفل متلعثم في الكلام فستساعدك كثي...\n296721    أنصت لطفلك باهتمام حافظ على تواصل العينين حال ...\n296722                                   التواصل مع الآخرين\n296723    قد يكون من المفيد للأطفال والوالدين والبالغين ...\n296724    لمزيد من المعلومات قم بزيارة مواقع الويب الخاص...\nName: text, Length: 296725, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"testing_df['text'] = testing_df['text'].apply(lambda x:   arabert_prep.preprocess(x))\ntesting_df['text']","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:48:47.608261Z","iopub.execute_input":"2023-02-10T23:48:47.609656Z","iopub.status.idle":"2023-02-10T23:48:53.072198Z","shell.execute_reply.started":"2023-02-10T23:48:47.609617Z","shell.execute_reply":"2023-02-10T23:48:53.070969Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0        هو حالة مرضية تعنى وجود دم فى البول و يمكن رؤي...\n1        إلا أنه فى الغالب لا يمكن إثبات ذلك إلا من خلا...\n2        قد لا تكون هناك أى أعراض يشتكى منها المريض سوى...\n3                         صعوبة فى التبول مع الشعور بحرقان\n4                               ارتفاع فى درجة حرارة الجسم\n                               ...                        \n36518    الحفاظ على وزن صحي إذا كان وزنك زائدا فإن إنقا...\n36519    زيادة الأنشطة البدنية قد تساعد ممارسة الأنشطة ...\n36520    الامتناع عن تناول المشروبات الكحولية يمكن للكح...\n36521    الامتناع عن التدخين يمكن أن يصيب التبغ جدران ا...\n36522    السيطرة على التوتر احرص على تقليل التوتر قدر ا...\nName: text, Length: 36523, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X = training_df['text']\ny = training_df['label']","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:48:53.074228Z","iopub.execute_input":"2023-02-10T23:48:53.074984Z","iopub.status.idle":"2023-02-10T23:48:53.080704Z","shell.execute_reply.started":"2023-02-10T23:48:53.074945Z","shell.execute_reply":"2023-02-10T23:48:53.079667Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test =X,testing_df['text'], y,testing_df['label'] #train_test_split(X, y, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:48:53.083225Z","iopub.execute_input":"2023-02-10T23:48:53.084276Z","iopub.status.idle":"2023-02-10T23:48:53.102669Z","shell.execute_reply.started":"2023-02-10T23:48:53.084239Z","shell.execute_reply":"2023-02-10T23:48:53.101459Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class BERTDataset():\n    def __init__(self, text, target, model_name, max_len, label_map):\n      super(BERTDataset).__init__()\n      self.text = text\n      self.target = target\n      self.tokenizer_name = model_name\n      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n      self.max_len = max_len\n      self.label_map = label_map\n      \n\n    def __len__(self):\n      return len(self.text)\n\n    def __getitem__(self,item):\n      text = str(self.text[item])\n      text = \" \".join(text.split())\n\n\n        \n      input_ids = self.tokenizer.encode(\n          text,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          truncation='longest_first'\n      )     \n    \n      attention_mask = [1] * len(input_ids)\n\n      # Zero-pad up to the sequence length.\n      padding_length = self.max_len - len(input_ids)\n      input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n      attention_mask = attention_mask + ([0] * padding_length)    \n      \n      return InputFeatures(input_ids=input_ids, attention_mask=attention_mask, label=self.label_map[self.target[item]])","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:48:53.106258Z","iopub.execute_input":"2023-02-10T23:48:53.106598Z","iopub.status.idle":"2023-02-10T23:48:53.117343Z","shell.execute_reply.started":"2023-02-10T23:48:53.106546Z","shell.execute_reply":"2023-02-10T23:48:53.116380Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"label_map = { v:index for index, v in enumerate(label_list_HARD) }\nprint(label_map)\ntrain_dataset = BERTDataset(X_train.to_list(),y_train.to_list(),model_name, max_len,label_map)\nval_dataset  = BERTDataset(X_test.to_list()   ,y_test.to_list()  ,model_name,  max_len, label_map)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:48:53.118600Z","iopub.execute_input":"2023-02-10T23:48:53.119579Z","iopub.status.idle":"2023-02-10T23:48:58.198136Z","shell.execute_reply.started":"2023-02-10T23:48:53.119540Z","shell.execute_reply":"2023-02-10T23:48:58.196169Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'Overview': 0, 'Causes': 1, 'Symptoms': 2, 'Treatment': 3, 'Diagnosis': 4}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/381 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adad213a26348d7b3dd4c0f4f836591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668c051f8d2c43de8be6f1a55945f01d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/805k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff525e5aaac4dcb827470d257e7a08c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91fa502cab504cc2a14cde0a62ce2354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2116c71dac9942c286a4b5fa9e5abb43"}},"metadata":{}}]},{"cell_type":"code","source":"def model_init():\n    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:49:00.477607Z","iopub.execute_input":"2023-02-10T23:49:00.477995Z","iopub.status.idle":"2023-02-10T23:49:00.483752Z","shell.execute_reply.started":"2023-02-10T23:49:00.477953Z","shell.execute_reply":"2023-02-10T23:49:00.482424Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p): #p should be of type EvalPrediction\n  preds = np.argmax(p.predictions, axis=1)\n  assert len(preds) == len(p.label_ids)\n  print(classification_report(p.label_ids,preds))\n  print(confusion_matrix(p.label_ids,preds))\n\n  # macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[0,1])\n  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n  macro_precision = precision_score(p.label_ids,preds,average='macro')\n  macro_recall = recall_score(p.label_ids,preds,average='macro')\n  acc = accuracy_score(p.label_ids,preds)\n  # c_repoert= classification_report(p.label_ids,preds))\n\n  return {\n      'macro_f1' : macro_f1,\n      # 'macro_f1_pos_neg' : macro_f1_pos_neg,  \n      'macro_precision': macro_precision,\n      'macro_recall': macro_recall,\n      'accuracy': acc,\n      # 'classification_report' :c_repoert\n  }","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:49:07.641278Z","iopub.execute_input":"2023-02-10T23:49:07.641989Z","iopub.status.idle":"2023-02-10T23:49:07.649182Z","shell.execute_reply.started":"2023-02-10T23:49:07.641951Z","shell.execute_reply":"2023-02-10T23:49:07.648173Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# HyperParameter Search","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\"./train\")\ntraining_args.evaluate_during_training = True\ntraining_args.adam_epsilon = 1e-8\ntraining_args.lr_scheduler_type = 'cosine'\ntraining_args.fp16 = True\ntraining_args.per_device_train_batch_size = 16\ntraining_args.per_device_eval_batch_size = 16\ntraining_args.gradient_accumulation_steps = 2\ntraining_args.num_train_epochs= 8\ntraining_args.evaluation_strategy = EvaluationStrategy.EPOCH\n# training_args.logging_steps = 200\ntraining_args.save_steps = 100000\n# training_args.save_steps = \n#training_args.eval_steps = \ntraining_args.disable_tqdm = True\n# print(\"Logging Step:\", training_args.logging_steps)\n# print(\"Eval Step:\",training_args.eval_steps)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:49:32.794738Z","iopub.execute_input":"2023-02-10T23:49:32.795744Z","iopub.status.idle":"2023-02-10T23:49:32.928419Z","shell.execute_reply.started":"2023-02-10T23:49:32.795701Z","shell.execute_reply":"2023-02-10T23:49:32.927086Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = (len(X_train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\ntotal_steps = steps_per_epoch * training_args.num_train_epochs\nprint(steps_per_epoch)\nprint(total_steps)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:49:40.201111Z","iopub.execute_input":"2023-02-10T23:49:40.201934Z","iopub.status.idle":"2023-02-10T23:49:40.208444Z","shell.execute_reply.started":"2023-02-10T23:49:40.201890Z","shell.execute_reply":"2023-02-10T23:49:40.206893Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"9272\n74176\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    args=training_args,\n    train_dataset=train_dataset, \n    eval_dataset=val_dataset, \n    model_init=model_init,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:49:55.263576Z","iopub.execute_input":"2023-02-10T23:49:55.263997Z","iopub.status.idle":"2023-02-10T23:50:22.690460Z","shell.execute_reply.started":"2023-02-10T23:49:55.263963Z","shell.execute_reply":"2023-02-10T23:50:22.689343Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\nModel config BertConfig {\n  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3,\n    \"LABEL_4\": 4\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 64000\n}\n\nhttps://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpoyj2b_pd\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e1c0070f0e46b2ab0a0c219c165b63"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/c0183275aaa055648fb44d6c24d9604b860b02398c7d9c7bea64257cdb87a56e.9e74f71b2acf9ee9289bd6ab56938934df2792f595150523e3f83558666a9676\ncreating metadata file for /root/.cache/huggingface/transformers/c0183275aaa055648fb44d6c24d9604b860b02398c7d9c7bea64257cdb87a56e.9e74f71b2acf9ee9289bd6ab56938934df2792f595150523e3f83558666a9676\nloading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c0183275aaa055648fb44d6c24d9604b860b02398c7d9c7bea64257cdb87a56e.9e74f71b2acf9ee9289bd6ab56938934df2792f595150523e3f83558666a9676\nSome weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> # Regular Training","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\"./train\")\ntraining_args.evaluate_during_training = True\ntraining_args.adam_epsilon = 1e-8\ntraining_args.learning_rate = 1e-4\ntraining_args.fp16 = True\n# training_args.per_device_train_batch_size =16\n# training_args.per_device_eval_batch_size = 16\n\ntraining_args.per_device_train_batch_size = 16  \ntraining_args.per_device_eval_batch_size = 16\n\n\ntraining_args.gradient_accumulation_steps = 2\ntraining_args.num_train_epochs= 5\n\n\nsteps_per_epoch = (len(X_train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\ntotal_steps = steps_per_epoch * training_args.num_train_epochs\nprint(steps_per_epoch)\nprint(total_steps)\n#Warmup_ratio\nwarmup_ratio = 0.1\ntraining_args.warmup_steps = total_steps*warmup_ratio # or you can set the warmup steps directly \n\n# training_args.load_best_model_at_end=True\n\ntraining_args.evaluation_strategy = EvaluationStrategy.EPOCH\n# training_args.logging_steps = 200\ntraining_args.save_steps = 100000 #don't want to save any model, there is probably a better way to do this :)\ntraining_args.seed = 42\ntraining_args.disable_tqdm = False\ntraining_args.lr_scheduler_type = 'cosine'","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:50:28.788108Z","iopub.execute_input":"2023-02-10T23:50:28.788505Z","iopub.status.idle":"2023-02-10T23:50:28.802532Z","shell.execute_reply.started":"2023-02-10T23:50:28.788472Z","shell.execute_reply":"2023-02-10T23:50:28.801452Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"},{"name":"stdout","text":"9272\n46360\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n) ","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:50:40.224130Z","iopub.execute_input":"2023-02-10T23:50:40.224531Z","iopub.status.idle":"2023-02-10T23:50:42.626828Z","shell.execute_reply.started":"2023-02-10T23:50:40.224497Z","shell.execute_reply":"2023-02-10T23:50:42.625767Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\nModel config BertConfig {\n  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3,\n    \"LABEL_4\": 4\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 64000\n}\n\nloading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c0183275aaa055648fb44d6c24d9604b860b02398c7d9c7bea64257cdb87a56e.9e74f71b2acf9ee9289bd6ab56938934df2792f595150523e3f83558666a9676\nSome weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T23:50:51.897806Z","iopub.execute_input":"2023-02-10T23:50:51.898187Z","iopub.status.idle":"2023-02-11T04:31:19.577345Z","shell.execute_reply.started":"2023-02-10T23:50:51.898152Z","shell.execute_reply":"2023-02-11T04:31:19.576454Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 296725\n  Num Epochs = 5\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 64\n  Gradient Accumulation steps = 2\n  Total optimization steps = 23180\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.10 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230210_235106-2ihlq7vy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/php-hamdan/huggingface/runs/2ihlq7vy\" target=\"_blank\">./train</a></strong> to <a href=\"https://wandb.ai/php-hamdan/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='23180' max='23180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [23180/23180 4:39:57, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=23180, training_loss=0.22259599436347705, metrics={'train_runtime': 16827.6458, 'train_samples_per_second': 88.166, 'train_steps_per_second': 1.377, 'total_flos': 1.9518156431608013e+17, 'train_loss': 0.22259599436347705, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T04:31:19.579478Z","iopub.execute_input":"2023-02-11T04:31:19.580920Z","iopub.status.idle":"2023-02-11T04:33:53.773315Z","shell.execute_reply.started":"2023-02-11T04:31:19.580878Z","shell.execute_reply":"2023-02-11T04:33:53.772450Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 36523\n  Batch size = 32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1142' max='1142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1142/1142 02:33]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97      3572\n           1       0.96      0.95      0.96      6114\n           2       0.95      0.97      0.96      7663\n           3       0.99      0.98      0.99     13022\n           4       0.99      0.98      0.98      6152\n\n    accuracy                           0.97     36523\n   macro avg       0.97      0.97      0.97     36523\nweighted avg       0.97      0.97      0.97     36523\n\n[[ 3454    58    31    17    12]\n [   49  5830   173    57     5]\n [   31   110  7461    34    27]\n [   22    71    89 12821    19]\n [   14    24    78    27  6009]]\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.09704025834798813,\n 'eval_macro_f1': 0.9711319854833025,\n 'eval_macro_precision': 0.9712355148194298,\n 'eval_macro_recall': 0.971094838649495,\n 'eval_accuracy': 0.9740437532513758,\n 'eval_runtime': 154.1768,\n 'eval_samples_per_second': 236.89,\n 'eval_steps_per_second': 7.407,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntrainer._save(\"/kaggle/working/AraBERTV02_model\")\ntokenizer.save_pretrained(\"/kaggle/working/AraBERTV02_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2023-02-11T04:33:53.777757Z","iopub.execute_input":"2023-02-11T04:33:53.780229Z","iopub.status.idle":"2023-02-11T04:33:56.676656Z","shell.execute_reply.started":"2023-02-11T04:33:53.780194Z","shell.execute_reply":"2023-02-11T04:33:56.675749Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\nModel config BertConfig {\n  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 64000\n}\n\nloading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6d195dfa0ab2ff9e30278a35699eb13eeb3a69731e8458ef8af7c9598e05ee99.292c9b563974181697c28c4ae4b6899dcaa7bdcf146b5682a389ef18208389a9\nloading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/cdf2434ef735735269b56feeae539fb93d28d674f4b335e2f08ed38960ea51e7.cf8d1bcc109a4ae89b00382b3c7dce421b2534c25751be3d5156322fc427fc12\nloading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4318ddb7acd24ce55328cd47235c5aaf88d4925a8a257863c4ebcc0852985d2c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\nloading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f8b57973211cf183180900e4646e204fe0c492b6129df1509f0e8ddc02369a05.130b8595f3c840efdfe3e2e9d3926b3c47a1a69aa1a7f6660fd11be56bf0d5fc\nloading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\nModel config BertConfig {\n  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 64000\n}\n\nSaving model checkpoint to /kaggle/working/AraBERTV02_model\nConfiguration saved in /kaggle/working/AraBERTV02_model/config.json\nModel weights saved in /kaggle/working/AraBERTV02_model/pytorch_model.bin\ntokenizer config file saved in /kaggle/working/AraBERTV02_tokenizer/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/AraBERTV02_tokenizer/special_tokens_map.json\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/AraBERTV02_tokenizer/tokenizer_config.json',\n '/kaggle/working/AraBERTV02_tokenizer/special_tokens_map.json',\n '/kaggle/working/AraBERTV02_tokenizer/vocab.txt',\n '/kaggle/working/AraBERTV02_tokenizer/added_tokens.json',\n '/kaggle/working/AraBERTV02_tokenizer/tokenizer.json')"},"metadata":{}}]}]}